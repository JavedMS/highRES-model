# grid:
# snakemake --rerun-incomplete --resources mem_mb=84000 --executor slurm --default-resources \ 
# slurm_account=ec85 runtime=5760 mem_mb_per_cpu=21000 cpus_per_task=5  \
# --use-conda --keep-going -j unlimited


# region:
# snakemake --resources mem_mb=700000 --slurm --default-resources \
# slurm_account=ec85 runtime=30 mem_mb_per_cpu=1100 cpus_per_task=4 \
# --use-conda --cluster-cancel scancel --keep-going -j unlimited

# TODO: Default profile is Fox, HPC, profile
configfile: "config/cluster_system_os_config.yaml"


import itertools
import pathlib

import pandas as pd
import json

#date_range=["2010-01-01","2010-12-31"]
date_range=["01-01","12-31"]

# Inputs to be used as wildcards to make changes based on the requirement
weatheryears = [
    #"1995",%
    "2010"
]

demandyears = [
    "2030",
    "2040",
    "2050"
]

spatials = [
    #"grid",
    "region"    
]

trans = [
    "DefaultYes",
    "DefaultNO",
    #"FIXEDOH",
    "LOWOH"
]

import_xxx = [
    0,
    1,
    2,
    #3,
    5,
    #7,
    10,
]

# [Solar, Windonshore, Windoffshore, Windoffshorefloating],
# No clear division between offshore & offshore floating. set solar and onshore only and optimize the ratio b/w these two...
varnewpcapQ = {
    'OPT': [1, 1, 1, 1],    #Scenario to freely optimize the newpcap. didnot change OPT name itself
    'QS1': [0.245, 0.34, 1, 1],
    #'QS2': [0.15, 0.4, 0.25, 0.20],
} 
varnewpcapQ_keys = list (varnewpcapQ.keys())

cutoffs_solar = [0.09]
cutoffs_onwind = [0.15]
cutoffs_offwind = [0.20]

# CORINE solar scenarios for invert=True
corine_solar = {
    'CSD': [1, 3, 7, 8, 9, 26, 27, 28, 29, 30, 31, 32, 33],
    #'CSDHF': [3, 7, 8, 9, 26, 30, 31, 32, 33],     #no Agriculture in default scenario
}

# Create the list of keys representing CORINE codes
corine_solar_keys = list(corine_solar.keys())

# CORINE onshore_wind scenarios for invert=True
corine_onshore = {
    'CWD': [1, 2, 3, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,
            24 ,25, 26, 27, 28, 29, 30, 31, 32, 33, 42, 43, 44],
    'CWDH': [3, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,
            24 ,25, 26, 27, 28, 29, 30, 31, 32, 33, 42, 43, 44],
    'CWDHA': [3, 6, 7, 8, 9, 23, 24 ,25, 26, 27, 28, 29, 30, 31, 32, 33, 42, 43, 44],
    'CWDHAF': [3, 6, 7, 8, 9, 26, 27, 28, 29, 30, 31, 32, 33, 42, 43, 44],

}

# Create the list of keys representing CORINE codes
corine_onshore_keys = list(corine_onshore.keys())

Nibio_solar = {
    'NSD': ['10', '50', '60'],
}
Nibio_solar_keys = list(Nibio_solar.keys())

Nibio_onwind = {
    'NWD': ['10', '20', '30', '50', '60', '80', '81'],
}
Nibio_onwind_keys = list(Nibio_onwind.keys())

# fylke wise technology constraint = (solar, wind)
fylke_tech_limit = {
        "fylketechD": {"NO03": [1, 1], "NO11": [1, 1], "NO15": [1, 1],
                      "NO18": [1, 1], "NO30": [1, 1], "NO34": [1, 1],
                      "NO38": [1, 1], "NO42": [1, 1], "NO46": [1, 1],  
                     "NO50": [1, 1], "NO54": [1, 1], 
                     },

        "fylketechC": {"NO03": (0.1337, 0.01242), "NO11": (0.0842, 0.1242), "NO15": (0.0446, 0.0994),
                      "NO18": (0.0495, 0.1429), "NO30": (0.1485, 0.0311), "NO34": (0.104, 0.0435),
                      "NO38": (0.0941, 0.0497), "NO42": (0.1485, 0.04348), "NO46": (0.0693, 0.1491),  
                      "NO50": (0.0644, 0.1615), "NO54": (0.0594, 0.1429), 
                   },

}
fylke_tech_keys = list(fylke_tech_limit.keys())


# Use product to create all possible combinations of the values in the lists
scenarios_product = list(itertools.product(weatheryears, demandyears, spatials, trans, import_xxx, varnewpcapQ_keys,
                         corine_solar_keys, corine_onshore_keys, Nibio_solar_keys, Nibio_onwind_keys, fylke_tech_keys,
                         cutoffs_solar, cutoffs_onwind, cutoffs_offwind))

# Create the DataFrame from the list of all combinations
column_names = ['weatheryears', 'demandyears', 'spatials', 'trans', 'import_xxx', 'varnewpcapQ', 'corines_solar',
                'corines_onshore','Nibios_solar', 'Nibios_onwind', 'fylke_techs', 'cutoffs_solar', 'cutoffs_onwind',
                'cutoffs_offwind']
scenarios = pd.DataFrame(scenarios_product, columns=column_names)

#generating scenarios: six columns with naturs, faunas, samis, neighs, nothing, nowwind
# scenarios = (
#     pd.DataFrame(itertools.product(values, repeat=3))
#     .rename(
#         columns={
#             0: "naturs",
#             1: "faunas",
#             2: "samis",
#         }
#     )
#     .assign(neighs="Low")
#     .T.assign(nothing="None", nowind="High")
#     .T.reset_index(drop=True)
# )


# to run everything, comment the next line out!
# scenarios = scenarios.query("neighs=='None' or neighs=='Extreme' or solars=='High'")

# drop pointless cutoff grid scenarios
#scenarios = scenarios.drop(
#    scenarios.query("spatials=='grid' and cutoffs_wind!=0.0").index     # limiting the cutoffs_wind list to only 0.15
#).reset_index()

# droplist = [6,7,2,0,28]
# scenarios = scenarios.drop(droplist,axis=0)

weatheryear = scenarios.weatheryears.to_list()
demandyear = scenarios.demandyears.to_list()
spatials = scenarios.spatials.to_list()
trans = scenarios.trans.to_list()
import_xxx = scenarios.import_xxx.to_list()
varnewpcapQs = scenarios.varnewpcapQ.to_list()
corines_solar = scenarios.corines_solar.to_list()
corines_onshore = scenarios.corines_onshore.to_list() 
Nibios_solar = scenarios.Nibios_solar.to_list()
Nibios_onwind = scenarios.Nibios_onwind.to_list()
fylke_techs = scenarios.fylke_techs.to_list()
cutoffs_solar = scenarios.cutoffs_solar.to_list()
cutoffs_onwind = scenarios.cutoffs_onwind.to_list()
cutoffs_offwind = scenarios.cutoffs_offwind.to_list()

# in grams per kWh
co2target = round(0, 1)

# gamsfilesha256 = "d8e033699604d4474a1c9db59140749509f30383dee532c1e85165617620776b"
# gamsfilesha256 = "af4a97e52ff41b137a24fb517b03e0e8268d879b01c7aefd7cae3074467ebad1"
# gamsfilesha256 = "b8ff95b0bc41fa7bd18ff192eac69b54ead25d72a851656c0d9e8fe41ca50177"
# gamsfilesha256 = "9b1b86c582b18822fcf9c65045f9c68605e951957cd934cc1713f8cf00a5f375"
# gamsfilesha256 = "7c58219c0ab4320c806c0460ebba547c10838313c6a1f10f6e6640aab90a4838"
# gamsfilesha256 = "9cced6b80dad705f6963e4dee1c48af4b8170d42444bb269b049ea8627d6c0e5"
# gamsfilesha256 = "686cc7b751384f1f0401289c1da84f8454221b7eb146bf1b65eb5dae2d08c22a"
# gamsfilesha256 = "21a42507bb4c2b9be551a4f35012d1e6645ea3ab401feaee7467c1af88b25c00"
gamsfilesha256 = "c2664b9bbf178e43b36260c429b21e6eeec6a0f8e8f7c9b6a24b504a4bc8ce25"
#gamsfilesha256 = "8760c1dfea64d41adcc75c16a4e0902f076e9f3a4468e455ad1d7fc1094a8a1b"

CORRECTOR_YEAR = 2019
num_near_wind_parks = 10
num_parallel_processes = 64
hydro_res_min = 0.2

# Absolute path to your GAMS installation
gamspath = config["paths"]["gams"]

# Absolute path to the input data that is the same across all versions
shared_input_path = pathlib.Path(config["paths"]["shared_input"])

# Relative path the model code that is the same across all versions
# shared_code_path = "resources/4_model_code_shared/"
abs_shared_code_path = config["paths"]["abs_shared_code"]
# abs_shared_code_path = workflow.source_path("../resources/4_model_code_shared/")
# TODO: Get this to work, maybe with Pathlib

# Absolute path to the con directory:
abs_con_path = config["paths"]["abs_con"]

# Relative path to the geodata files that differentiate the scenarios
scenario_exclusions_path = "resources/scenario_exclusions/"

# Relative path to the results
# TODO: Vetle: --directory, flag for å sette results directory?
# resultspath = "results/"
resultspath = pathlib.Path(config["paths"]["resultsdir"])
pathlib.Path(resultspath).mkdir(parents=True, exist_ok=True)
# "/cluster/work/projects/ec85/joint-wind/model-aggregated/resultsoff/"

# Write scenarios to file, so results analysis script can check if they are all
# available.
scenarios.to_csv(resultspath / "scenarios.csv", sep="\t")

# Relative path to the built model and built inputs
yearonlypart = "models/{year}/"
#scenariopart = "{natur}_{fauna}_{sami}_{neigh}_{solar}_{spatial}_{cutoff_wind}/"
scenariopart = "{year}_{dem_yr}_{spatial}_{trans}_{Importx}_{varnewpcapQ}_{corine_solar}_" + \
                "{corine_onshore}_{Nibio_solar}_{Nibio_onwind}_{fylke_tech}_{cutoff_solar}_" + \
                 "{cutoff_onwind}_{cutoff_offwind}/"
modelpathyearonly = resultspath / yearonlypart
modelpath = modelpathyearonly / scenariopart
allyearpath = resultspath / "models/allyears/"
logpath = yearonlypart + scenariopart


localrules:
    all,
    build_gams,
    add_transmission_type,
    build_cplex_opt,
    build_technoeconomic_inputs,
    import_export_changes,
    ensure_gams_template,
    rename_demand_file,
    build_regions_file,
    build_zones_file,
    build_hydro_areas,
    build_weather,
    build_vre_areas_file,
    build_vre_file,
    build_vre_gdx,
    build_hydro_capfac,
    build_hydrores_inflow,
    link_hydrores_inflow,
    convert_results,
    bias_correct_wind,      #not in EU version
    extract_wind_cap2area,  #not in EU version
    build_cutoff,           #not in EU version
    build_vre_parquet,
    build_vre_csv,
    compress_vre_gdx,
    compress_hydrores_inflow,
    convert_results_db_parquet, #not in EU version


rule all:
    input:
        expand(
            modelpath / "results.db.compressed",
            zip,
            year=weatheryear,     # these are all wildcards of snakefile
            dem_yr=demandyear,
            spatial=spatials,
            trans=trans,
            Importx=import_xxx,
            varnewpcapQ=varnewpcapQs,
            corine_solar=corines_solar,
            corine_onshore=corines_onshore,
            Nibio_solar=Nibios_solar,
            Nibio_onwind=Nibios_onwind,
            fylke_tech=fylke_techs,
            cutoff_solar=cutoffs_solar, 
            cutoff_onwind=cutoffs_onwind,
            cutoff_offwind=cutoffs_offwind,
        ),


rule extract_wind_cap2area:
# TODO think about whether we really only should read from the high version
    # Reading only cap2area parameter from excel file & storing as windcap2area
    input:
        #odsdatabase="resources/highres_gb_ext_database_High.ods",
        odsdatabase="resources/highres_gb_ext_database_Low.ods",
    output:
        windcap2area=resultspath / "windcap2area",
    conda:
        "envs/build_windcap2area.yml"
    script:
        "scripts/build_windcap2area.py"


rule ensure_gams_template:
    input:
        "resources/highresraw.gms",
    output:
        gamsfile=ensure(resultspath / "highres.gms", sha256=gamsfilesha256),  
    run:
        import shutil
        
        shutil.copy2(input[0], output[0])


rule build_gams:
    input:
        rules.ensure_gams_template.output.gamsfile,
        #"resources/highres.gms",
    params:
        co2intensity=co2target,
        sharedcodepath=abs_shared_code_path,
        varnewpcapQ=lambda wildcards: varnewpcapQ[wildcards.varnewpcapQ],
        enable_fixed_ratios=lambda wildcards: False if wildcards.varnewpcapQ == 'OPT' else True,
        fylke_tech_limit=lambda wildcards: json.dumps(fylke_tech_limit),
    output:
        gamsfile2=modelpath / "highres1.gms",
    script:
        "scripts/build_gams.py"


rule add_transmission_type:
    input:
        rules.build_gams.output.gamsfile2,
    output:
        modelpath / "highres2.gms",
    script:
        "scripts/build_transmission.py"

rule build_cplex_opt:
    input:
        "resources/cplex.opt",
        #ancient("resources/cplex.opt"), # TODO: What does this line do?
    output:
        modelpath / "cplex.opt",
    run:
        import shutil
        
        shutil.copy2(input[0], output[0])


rule build_zones_file:
    input:
        "resources/zones.csv",
        "workflow/scripts/build_zones.py",  #input/output paths always relative to the terminal
    output:
        modelpath / "zones.dd",
    script:
        "scripts/build_zones.py"        #script paths relative to the snakefile path

# where to make changes highres_gb_ext_database_Low for costs...?
# storage_costs: Li-ion battery, Storage+IDC stands for?,
# generator_costs: chnages from EU version --> solar, wind onshore, wind offshore, hydroROR, HydroRes and other techs as well.
# gen: windoffshore is not added. is it excluded from analysis? Added by me in highres_gb_ext_database_Low.ods 
# transmission allowed: distance and cap btw fylkes 
# sheets where changes to be made regarding costs: generator_costs (in capex of realted year & technology)...
# storage_costs: column_N (Storage (£k/MWh)), transmission_costs: (future transmission installation could be contrained based on scenarios)
# Transmission costs changing need to check further
# Import as technology used in excel file: its costs/capacities in gen, gen_lim_z, and gen_exist_z are unclear...
# gen_lim_z: sheet where fixed/upper limit of technologies defined. Windoffshore is fixed to zero currently?? windonshore and solar are not limited
# gen_exist_z: solar existing capacity is not added currently in technology and need to be added
# existing capacities of windoffshore, windonshore, and import are there in excel file

rule build_technoeconomic_inputs:
    input:
        "resources/zones.csv",          # zones need to change to get related region values from excel files
        "resources/gb_ext_scenarios.xls",
        #"resources/highres_gb_ext_database_{solar}.ods",    #solar wild card used here
        "resources/highres_gb_ext_database_Low.ods",
        #"resources/highres_gb_ext_database_High.ods",
        europecountriescsvlocation="resources/europe_countries.csv",
        #europedemandcsvlocation="resources/europe_demand_2006-2015.csv", #nonrescale demand from 1951
        europedemandcsvlocation=abs_con_path + "europe_demand_{dem_yr}.csv",
        data2dd="workflow/scripts/data2dd_funcs.py",
    conda:
        "envs/build_technoeconomic.yml",
    output:
        modelpath / "{year}_temporal.dd",       # generating hourly temporal resolution
        modelpath / "BASE_co2_budget.dd",       # non_used file
        #BASEgendd=modelpath / "BASE_gen.dd",
        modelpath / "BASE_store.dd",
        modelpath / "trans.dd",
        demandfile=temp(modelpath / "BASE_norescale_demand_{year}.dd"), #only demand of wildcard year
        BASEgendd=modelpath / "BASE_gen.dd",
    params:
        date_range=date_range,
    script:
        "scripts/gb_ext_data2dd.py"


rule import_export_changes:
    input:
        rules.build_technoeconomic_inputs.output.BASEgendd,
    output:
        BASEgennewdd=modelpath / "BASE_gen_final.dd",
    params:
        ImportX=lambda wildcards: float(wildcards.Importx),
    script:
        "scripts/import_input_change.py"

rule rename_demand_file:
    input:
        rules.build_technoeconomic_inputs.output.demandfile,
    output:
        modelpath / "BASE_demand_{year}.dd",
    run:
        import shutil

        shutil.copy2(input[0], output[0])


rule build_hydro_areas:
    input:
        "resources/zones.csv",
    output:
        areashydro=temp(allyearpath / "available_area.txt"),
    script:
        "scripts/build_hydro_areas.py"

# CF corrected only for onshore data at grid cell level?
# params impact in corrected CF i.e., num_near_wind_parks?
# scripts versus notebooks?
rule bias_correct_wind:
    input:
        era5_corrector=abs_con_path + f"europe-era5_{CORRECTOR_YEAR}.nc",
        #era5_corrector=f"resources/bias/europe-era5_{CORRECTOR_YEAR}.nc",
        era5=abs_con_path + "europe-era5_{year}.nc",
        #era5="resources/bias/europe-era5_{year}.nc",
        wind_parks="resources/bias/nve_wind_parks.geojson",
        production="resources/bias/TimeSeries_UTC_kWh_2022_all.csv",
        europeshape="resources/bias/Onshore_EU-NUTS0_NO-NUTS3_UK-NG.geojson",
    output:
        uncorrected=modelpathyearonly / "uncorrected_wind_capacity_factors_{year}.nc",
        corrected=modelpathyearonly / "corrected_wind_capacity_factors_{year}.nc",
        corrected_simple=modelpathyearonly
        / "corrected_simple_wind_capacity_factors_{year}.nc",
        corrected_for_highres=modelpathyearonly
        / "corrected_wind_capacity_factors_{year}.parquet",
    params:
        corrector_year=CORRECTOR_YEAR,
        num_near_wind_parks=num_near_wind_parks,
        num_parallel_processes=num_parallel_processes,
        date_range=date_range,
    resources:
        nodes=num_parallel_processes,       #will be ignored other than cluster plateforms
    conda:
        "envs/environment.yaml",
    script:
        "scripts/bias_correct_wind.py"

# excluding all those grid cells having CF less than cut_off
rule build_cutoff:
    input:
        changedbiaswind=rules.bias_correct_wind.output.corrected_for_highres,
    output:
        exclusiontiff=modelpathyearonly / "cf_exclusion_{cutoff_onwind}.tif",
        #exclusiontiff=modelpathyearonly / "cf_exclusion_{cutoff_wind}.tif",
        #exclusiontiff=modelpathyearonly / "cf_exclusion_{cutoff_onwind}.tif",
        
    conda:
        "envs/implement_cutoff.yml",
#    params:
#        cutoff_onwind=cutoff_onwind,    
    notebook:
        "notebooks/build_cutoff_tiff.py.ipynb"


# this ensures that if cut_off is zero, no need to run the above rule
def cutoff_needed(wildcards):
#def cutoff_needed():
    returndict = {}
    if wildcards.cutoff_onwind != str(0.0):
    #if cutoff_values["onwind"] != 0.0:
        returndict = {"cutoffexclusiontiff": rules.build_cutoff.output.exclusiontiff}
    return returndict

# can be removed
# def myfunc(wildcards):
#     returndict = {}
#     if wildcards.natur != "None" and wildcards.natur != "Extreme":
#         returndict[
#             "naturex"
#         ] = scenario_exclusions_path + "Natur_{wildcards.natur}_Exc.zip".format(
#             wildcards=wildcards       # if the condition is met, returning the file path, i.e., {"faunaex": "/path/to/exclusions/Fauna_high_Exc.zip"}
#         )
#     if wildcards.neigh != "None" and wildcards.neigh != "Extreme":
#         returndict[
#             "neighex"
#         ] = scenario_exclusions_path + "Neigh_{wildcards.neigh}_Exc.zip".format(
#             wildcards=wildcards
#         )
#     return returndict

# Further base exclusions I can add are:
# Tech_All_Exc.zip: related to windonshore only: roads/railway 200m buffer, Airports 2km, watercourses/waterbodies/glaciers exclude
# Neigh_Low_Exc.zip: related to windonshore only: Buildings buffer 400m, visibility from populated areas 1Km buffer, ski/biking/walking routes 20m buffer
# Natur_High_Exc.zip: contains unqiue seven IUCN [0-6] numbers, categorizing the protected areas. 0: none IUCN classified areas...

rule build_weather:
    input:
        unpack(cutoff_needed),
        #unpack(myfunc),
        WDPA1a=shared_input_path / "geodata/onshore/WDPA_Ia_100.tiff",
        WDPA1b=shared_input_path / "geodata/onshore/WDPA_Ib_100.tiff",
        WDPA2=shared_input_path / "geodata/onshore/WDPA_II_100.tiff",
        WDPA3=shared_input_path / "geodata/onshore/WDPA_III_100.tiff",
        WDPA4=shared_input_path / "geodata/onshore/WDPA_IV_100.tiff",
        elevation=shared_input_path / "geodata/onshore/2000m.shp.zip",
        slope=shared_input_path / "geodata/onshore/15degrees.shp.zip",
        euroshape=shared_input_path / "geodata/onshore/shapes/NO-NUTS3.geojson",
        eurooffshoreshape=shared_input_path
        / ("geodata/offshore/BOTTOM_MOUNTED_EUROPE_NUTS0" "_NORWAY_NUTS3.geojson"),
        eurooffshorefloatingshape=shared_input_path
        / ("geodata/offshore/FLOATING_EUROPE_NUTS0_NORWAY_NUTS3.geojson"),
        weatherdata=shared_input_path / "weatherdata/europe_{year}.nc",
        corine=shared_input_path / "geodata/onshore/corine.tif",
        #cap2area="resources/highres_gb_ext_database_{solar}.ods",
        #cap2area=rules.extract_wind_cap2area.output.windcap2area,
        cap2area=ancient("resources/windcap2area"),         #it is assumed available already
        wind_parks="resources/bias/nve_wind_parks.geojson",
        pvlow=scenario_exclusions_path + "PV_Low_Exc.zip",
        windlow=scenario_exclusions_path + "co.geotiff",
        AR250=scenario_exclusions_path + "0000_ar250_25833_gdb.gdb",
        #tech=scenario_exclusions_path + "Techn_All_Exc.zip",
        #neighex=scenario_exclusions_path + "Neigh_Low_Exc.zip",     #added as base exclusion for me, is it ok?
        #naturex=scenario_exclusions_path + "Natur_{natur}_Exc.zip",
        changedbiaswind=rules.bias_correct_wind.output.corrected_for_highres,
        #cutoffexclusiontiff=rules.build_cutoff.output.exclusiontiff
    output:
        cf_exclusion_solar=temp(modelpath / "cf_exclusion_solar.tif"),  #exclusion only based on CF cutoff
        #cf_exclusion_windon=temp(modelpath / "cf_exclusion_windon.tif"), #Could be removed
        cf_exclusion_windoff=temp(modelpath / "cf_exclusion_windoff.tif"),
        cf_exclusion_windoff_floating=temp(modelpath / "cf_exclusion_windoff_floating.tif"),
        indreg=temp(modelpath / "indices_region.csv"),
        areassolar=temp(modelpath / "areas_norway_grid_solar.csv"),
        areaswindonshore=temp(modelpath / "areas_norway_grid_wind_onshore.csv"),
        areaswindoffshore=temp(modelpath / "areas_norway_grid_wind_offshore.csv"),
        areaswindoffshorefloating=temp(modelpath / "areas_norway_grid_wind_offshore_floating.csv"),
        changedbiaswindcsv=temp(modelpath / "capacity-factors_wind_norway-g_{year}.csv"),
        #capfacfile_solar=temp(modelpath / "capacity-factors_solar_norway-g_{year}.csv"),
        capfacfile_offshore=temp(modelpath / "capacity-factors_offshore_norway-g_{year}.csv"),
        # FIXME the files indreg and cf_exclusion_{solar,windon,windoff} are
        # only necessary under some conditions currently when those are not met,
        # we create an empty file
        # the cleaner solution might be to outsource the creation of that file
        # to an extra rule and have an input function conditional on the
        # wildcard spatial for that rule
    conda:
        "envs/build_weather.yml"
    log:
        notebook="logs/notebooks/" + logpath + "highRES-Norway_grid.py.ipynb",
    resources:
        mem_mb=50000,  # TODO: Find out how much this rule needs,
        # should be constant (regional/grid)
        nodes=12,
    params:
        sharedinputpath=shared_input_path,
        corine_solar=lambda wildcards: corine_solar[wildcards.corine_solar],
        corine_onshorewind=lambda wildcards: corine_onshore[wildcards.corine_onshore],
        Nibio_solar=lambda wildcards: Nibio_solar[wildcards.Nibio_solar],
        Nibio_onshorewind=lambda wildcards: Nibio_onwind[wildcards.Nibio_onwind],
        date_range=date_range
        #cutoffs=cutoff_values,
    notebook:
        "notebooks/highRES-Norway_grid.py.ipynb"


rule build_hydro_capfac:
# these inputs are not used in notebook, rather directly retrieved using path
    input:
        eiahydrogen="resources/EIA_hydro_generation_1995_2000_2014.csv",
        vannkraft="resources/Vannkraftverk.csv",
        hydroinstalledcap="resources/hydro_installed_cap.tsv",
    output:
        hydrororcapfac=temp(
            modelpathyearonly / "capacity-factors_hydro_norway-3_{year}.csv"
        ),
        hydroresinfl=temp(modelpathyearonly / "inflow_hydro-res_norway-3_{year}.csv"),
    conda:
        "envs/build_hydro_capfac.yml"
    params:
        sharedinputpath=shared_input_path,
        date_range=date_range,
    notebook:
        "notebooks/highRES_norway3_hydro.py.ipynb"


def regionsonlyforgrid(wildcards):
    returndict = {}
    if wildcards.spatial == "grid":
        returndict["indreg"] = rules.build_weather.output.indreg
    return returndict


rule build_regions_file:
    input:
        "workflow/scripts/build_regions.py",
        unpack(regionsonlyforgrid),
        zonescsv="resources/zones.csv",
        #rules.build_weather.output.indreg,
    output:
        regionsdd=modelpath / "_regions.dd",
    script:
        "scripts/build_regions.py"


# def build_vre_areas_file_func(wildcards):
#    returndict = {}
#    if wildcards.neigh != "Extreme":
#        returndict['areaswindon'] = rules.build_weather.output.areaswindonshore
#    return returndict


rule build_vre_areas_file:
    input:
        areashydro=rules.build_hydro_areas.output.areashydro,
        # unpack(build_vre_areas_file_func),
        areassolar=rules.build_weather.output.areassolar,
        areaswindon=rules.build_weather.output.areaswindonshore,
        areaswindoff=rules.build_weather.output.areaswindoffshore,
        areaswindofffloating=rules.build_weather.output.areaswindoffshorefloating,
        vreareaheader="resources/vre_areas_header.txt",
        genericfooter="resources/generic_footer.txt",
    output:
        modelpath / "vre_areas_{year}_.dd",     #main_file
        unsorted=temp(modelpath / "vre_areas_unsorted.txt"),
        areassorted=temp(modelpath / "vre_areas_sorted.txt"),
    script:
        "scripts/build_vre_areas_file.py"



rule build_hydrores_inflow:
    input:
        hydroresinfl=rules.build_hydro_capfac.output.hydroresinfl,
    output:
        inflowgdx=modelpathyearonly / "hydro_res_inflow_{year}.gdx",
    shell:
        #"""
        #{gamspath} csv2gdx {input.hydroresinfl} output={output.inflowgdx} ID=hydro_inflow
        #Index='(1,2,3)' Value='(4)' UseHeader=True StoreZero=True
        #"""
        gamspath + (
            "csv2gdx {input} output={output} ID=hydro_inflow "
            "Index='(1,2,3)' Value='(4)' UseHeader=True StoreZero=True"
        )


rule compress_hydrores_inflow:
    input:
        rules.build_hydrores_inflow.output.inflowgdx,
    output:
        compressdone=touch(modelpathyearonly / "hydrores_inflow_gdx.compressed"),
    shell:
        gamspath + "gdxcopy -V7C -Replace {input}"


rule link_hydrores_inflow:
    input:
        rules.compress_hydrores_inflow.output.compressdone,
        rules.build_hydrores_inflow.output.inflowgdx,
    output:
        inflowgdx=modelpath / "hydro_res_inflow_{year}.gdx",    #shifting hydro_res_inlfow from modelpathyearonly path to modelpath.
    shell:
        "ln -sr {input[1]} {output}"

# vre_file contains: windon, windoff, solar, and hydroror CF.
rule build_vre_file:
    input:
        #cfsng=rules.build_weather.output.capfacfile_solar,       #contains solar CF
        cfwng=rules.build_weather.output.capfacfile_offshore,
        cfhn3=rules.build_hydro_capfac.output.hydrororcapfac,
        changedbiaswindcsv=rules.build_weather.output.changedbiaswindcsv,   #contains corrected windonshore CF
    output:
        vrefile=temp(modelpath / "vre_{year}_.csv"),
    shell:
        (
            "cat {input[cfwng]} {input[changedbiaswindcsv]} {input[cfhn3]} | sed 's/bottom//'"
            " > {output[vrefile]}"
        )


rule build_vre_parquet:
    input:
        rules.build_vre_file.output.vrefile,
    output:
        modelpath / "vre_{year}_.parquet",
    conda:
        "envs/build_vre_parquet.yml"
    script:
        "scripts/build_vre_parquet.py"


rule build_vre_csv:
    input:
        modelpath / "vre_{year}_.parquet",
    output:
        csvgdx=temp(modelpath / "vre_{year}_tmp.csv"),
    conda:
        "envs/build_vre_parquet.yml"
    script:
        "scripts/build_vre_csv.py"


rule build_vre_gdx:
    input:
        #rules.build_vre_csv.output.csvgdx,
        rules.build_vre_file.output.vrefile,
    output:
        bigvregdx=(modelpath / "vre_{year}_.gdx"),
    shell:
        gamspath + (
            "csv2gdx {input} output={output} ID=vre_gen Index='(1,2,3)'"
            " Value='(4)' UseHeader=True StoreZero=True"
        )


rule compress_vre_gdx:
    input:
        rules.build_vre_gdx.output.bigvregdx,
    output:
        touch(modelpath / "vre_gdx.compressed"),
    shell:
        gamspath + "gdxcopy -V7C -Replace {input}"


""" def inputfilelist(wildcards):
    returndict = {}
    returndict['regionsfile'] = modelpath / "_regions.dd"
    returndict['zonesfile'] = modelpath / "zones.dd"
    returndict['temporalfile'] = modelpath / "{year}_temporal.dd"
    returndict['vreareafile'] = modelpath / "vre_areas_{year}_.dd"
    returndict['demandfile'] = modelpath / "BASE_demand_{year}.dd"
    returndict['capfacfilecompressed'] = modelpath / "vre_gdx.compressed"
    returndict['capfacfile'] = modelpath / "vre_{year}_.gdx"
    returndict['hydroresinflowfile'] = modelpath / "hydro_res_inflow_{year}.gdx"
    returndict['co2budgetfile'] = modelpath / "BASE_co2_budget.dd"
    returndict['genparamsfile'] = modelpath / "BASE_gen.dd"
    returndict['storeparamsfile'] = modelpath / "BASE_store.dd"
    returndict['transparamsfile'] = modelpath / "trans.dd"
    return returndict """


rule build_inputs:
    input:
        modelpath / "highres2.gms",
        modelpath / "cplex.opt",
        abs_shared_code_path + "highres_data_input.gms",
        abs_shared_code_path + "highres_hydro.gms",
        abs_shared_code_path + "highres_results.gms",
        abs_shared_code_path + "highres_storage_setup.gms",
        abs_shared_code_path + "highres_storage_uc_setup.gms",
        abs_shared_code_path + "highres_uc_setup.gms",
        modelpath / "_regions.dd",
        modelpath / "zones.dd",
        modelpath / "{year}_temporal.dd",
        modelpath / "vre_areas_{year}_.dd",
        modelpath / "BASE_demand_{year}.dd",
        modelpath / "vre_gdx.compressed",
        modelpath / "vre_{year}_.gdx",
        modelpath / "hydro_res_inflow_{year}.gdx",
        modelpath / "BASE_co2_budget.dd",
        #modelpath / "BASE_gen.dd",
        rules.import_export_changes.output.BASEgennewdd,
        modelpath / "BASE_store.dd",
        modelpath / "trans.dd",
    output:
        touch(modelpath / "inputs.finished"),


rule run_model:
    input:
        modelpath / "highres2.gms",
        modelpath / "cplex.opt",
        abs_shared_code_path + "highres_data_input.gms",
        abs_shared_code_path + "highres_hydro.gms",
        abs_shared_code_path + "highres_results.gms",
        abs_shared_code_path + "highres_storage_setup.gms",
        abs_shared_code_path + "highres_storage_uc_setup.gms",
        abs_shared_code_path + "highres_uc_setup.gms",
        modelpath / "inputs.finished",
        modelpath / "vre_{year}_.gdx",
    params:
        gamspath=gamspath,
        modelpath=str(modelpath),
        hydroresmin=hydro_res_min,
    # retries: 3
    log:
        str(modelpath) + "/highres2.lst",
        str(modelpath) + "/highres2.log",
    output:
        modelresults=protected(modelpath / "results.gdx"),
        modelresultsdd=protected(modelpath / "results.db"),
    script:
        "scripts/run_gams.sh"


rule convert_results:
    input:
        rules.run_model.output.modelresults,
    output:
        resultsdb=ensure(protected(modelpath / "results.db"), non_empty=True),
    shell:
        gamspath + "gdx2sqlite -i {input} -o {output} -fast"


rule convert_results_db_parquet:
    input:
        rules.run_model.output.modelresultsdd,
    output:
        compressdone=touch(modelpath / "results.db.compressed"),
    resources:
        mem_mb=50000,
    conda:
        "envs/build_vre_parquet.yml"
    script:
        "scripts/convert_results_sqlite_parquet.py"


# rule plot_bias_correction:
#     input:
#         era5=f"data/input/europe-era5_{CORRECTOR_YEAR}.nc",
#         production="data/input/TimeSeries_UTC_kWh_2022_all.csv",
#         europeshape="data/input/Onshore_EU-NUTS0_NO-NUTS3_UK-NG.geojson",
#         wind_parks="data/input/nve_wind_parks.geojson",
#         uncorrected_cap_factors=f"data/output/uncorrected_wind_capacity_factors_{CORRECTOR_YEAR}.nc",
#         corrected_cap_factors=f"data/output/corrected_wind_capacity_factors_{CORRECTOR_YEAR}.nc",
#         corrected_cap_factors_simple=f"data/output/corrected_simple_wind_capacity_factors_{CORRECTOR_YEAR}.nc",
#     output:
#         directory("data/output/plots"),
#     params:
#         corrector_year=CORRECTOR_YEAR,
#     conda:
#         "envs/environment.yaml"
#     script:
#         "scripts/plot_bias_correction.py"
